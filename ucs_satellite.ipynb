{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "378c2e7e",
   "metadata": {},
   "source": [
    "# Satellite Tracking Data\n",
    "## Union of Concerned Scientists\n",
    "\n",
    "Assembled by experts at the Union of Concerned Scientists (UCS), the [Satellite Database](https://www.ucs.org/resources/satellite-database) is a listing of the more than 7,560 operational satellites currently in orbit around Earth. It was first published on Dec 8, 2005 and most recently updated on May 1, 2023.\n",
    "\n",
    "![Loose Ends, Long Goodbyes Sat](img/lelg_sat_small.png)\n",
    "\n",
    "Much like orbital debris plummeting into the atmosphere, the dataset requires some cleanup. To begin, we'll import the necessary libraries, read the csv, and take a look at the total rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38dbff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7562, 68)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "file_path = \"data/UCS-Satellite-Database 5-1-2023.csv\"\n",
    "df = pd.read_csv(file_path) # you can read a csv, parquet, json, etc. Break it into chunks if the dataset is huge. Specify encoding if needed.\n",
    "df.shape # returns (rows, columns) in the df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f744e57",
   "metadata": {},
   "source": [
    "### Basic Cleaning\n",
    "#### Columns\n",
    "\n",
    "Let's check out the names of the columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3b492ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name of Satellite, Alternate Names',\n",
       "       'Current Official Name of Satellite', 'Country/Org of UN Registry',\n",
       "       'Country of Operator/Owner', 'Operator/Owner', 'Users', 'Purpose',\n",
       "       'Detailed Purpose', 'Class of Orbit', 'Type of Orbit',\n",
       "       'Longitude of GEO (degrees)', 'Perigee (km)', 'Apogee (km)',\n",
       "       'Eccentricity', 'Inclination (degrees)', 'Period (minutes)',\n",
       "       'Launch Mass (kg.)', ' Dry Mass (kg.) ', 'Power (watts)',\n",
       "       'Date of Launch', 'Expected Lifetime (yrs.)', 'Contractor',\n",
       "       'Country of Contractor', 'Launch Site', 'Launch Vehicle',\n",
       "       'COSPAR Number', 'NORAD Number', 'Comments', 'Unnamed: 28',\n",
       "       'Source Used for Orbital Data', 'Source', 'Source.1', 'Source.2',\n",
       "       'Source.3', 'Source.4', 'Source.5', 'Source.6', 'Unnamed: 37',\n",
       "       'Unnamed: 38', 'Unnamed: 39', 'Unnamed: 40', 'Unnamed: 41',\n",
       "       'Unnamed: 42', 'Unnamed: 43', 'Unnamed: 44', 'Unnamed: 45',\n",
       "       'Unnamed: 46', 'Unnamed: 47', 'Unnamed: 48', 'Unnamed: 49',\n",
       "       'Unnamed: 50', 'Unnamed: 51', 'Unnamed: 52', 'Unnamed: 53',\n",
       "       'Unnamed: 54', 'Unnamed: 55', 'Unnamed: 56', 'Unnamed: 57',\n",
       "       'Unnamed: 58', 'Unnamed: 59', 'Unnamed: 60', 'Unnamed: 61',\n",
       "       'Unnamed: 62', 'Unnamed: 63', 'Unnamed: 64', 'Unnamed: 65',\n",
       "       'Unnamed: 66', 'Unnamed: 67'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # prints names of all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b53ab",
   "metadata": {},
   "source": [
    "Pandas names blank columns 'Unnamed: X'. Let's see how many we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7eb6195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 32 unnamed columns.\n"
     ]
    }
   ],
   "source": [
    "unnamed_cols = [col for col in df.columns if col.startswith(\"Unnamed\")] #substring match\n",
    "\n",
    "print(f\"This dataset has {len(unnamed_cols)} unnamed columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604e4f1",
   "metadata": {},
   "source": [
    "Those can most likely be dropped, but let's make sure they are actually empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59b8fefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank_cols = [\n",
    "    col for col in df.columns\n",
    "    if df[col].isna().all() or df[col].astype(str).str.strip().eq(\"\").all() # remove whitespace (strip) then match for non-null but blank (eq)\n",
    "]\n",
    "\n",
    "blank_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb341c06",
   "metadata": {},
   "source": [
    "Mysterious. These aren't empty but I suspect they are an artifact and the data they contain isn't useful. Let's grab a couple and look at the value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d63157e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Unnamed: 37",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8d8c1c92-0768-4984-b885-243c18b16867",
       "rows": [
        [
         "Estimated",
         "484"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 1
       }
      },
      "text/plain": [
       "Unnamed: 37\n",
       "Estimated    484\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Unnamed: 37\"].value_counts() # sum of values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56f454",
   "metadata": {},
   "source": [
    "We see only a single value: *Estimated*. While technically this isn't empty, it isn't anything informative either. Let's check how many columns in the dataset contain only a single value (not counting nulls or blanks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2890eea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27 columns that contain only a single value.\n"
     ]
    }
   ],
   "source": [
    "single_value_cols = [\n",
    "    col for col in df.columns\n",
    "    if df[col]\n",
    "        .replace(r\"^\\s*$\", pd.NA, regex=True)\n",
    "        .dropna()\n",
    "        .nunique() == 1\n",
    "]\n",
    "\n",
    "print(f\"There are {len(single_value_cols)} columns that contain only a single value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbef973",
   "metadata": {},
   "source": [
    "We could dive into this deeper and look at all 27, but that's tedious and not an optimal use of our limited time in this universe. Instead, this looks like a great place to add a constraint:\n",
    "> If a column has only one value, it is not useful, and therefore we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99a31ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 5 unnamed columns.\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=single_value_cols)\n",
    "unnamed_cols = [col for col in df.columns if col.startswith(\"Unnamed\")]\n",
    "\n",
    "print(f\"This dataset has {len(unnamed_cols)} unnamed columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61e583f",
   "metadata": {},
   "source": [
    "That got rid of most of the `Unnamed` columns. While those remaining 5 have multiple values, at this point it's reasonable to assume they aren't useful. Likewise, the `Source` and `Comments` columns aren't relevant for our analysis, and the `Name of Satellite, Alternate Names` is redundant. We can drop those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f3f93a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 15 out of 41 columns.\n",
      "Remaining columns: 26\n"
     ]
    }
   ],
   "source": [
    "original_cols = len(df.columns)\n",
    "columns_to_drop = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if col.startswith(\"Unnamed\"):\n",
    "        columns_to_drop.append(col) # adds column\n",
    "    elif col.startswith(\"Source\"):\n",
    "        columns_to_drop.append(col)\n",
    "    elif col == \"Comments\":\n",
    "        columns_to_drop.append(col)\n",
    "    elif col == \"Name of Satellite, Alternate Names\":\n",
    "        columns_to_drop.append(col)\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "dropped_cols = len(columns_to_drop)\n",
    "remaining_cols = len(df.columns)\n",
    "\n",
    "print(f\"Dropped {dropped_cols} out of {original_cols} columns.\")\n",
    "print(f\"Remaining columns: {remaining_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7d14e3",
   "metadata": {},
   "source": [
    "We're still focused on columns, but let's take a quick detour to verify how many rows are in the dataset. This figure will be useful as a point of reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d78add9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 7562 total rows.\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(df)\n",
    "print(f\"The dataset has {total_rows} total rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da267512",
   "metadata": {},
   "source": [
    "We'll check which columns are missing the most values. This helps to decide which columns are useful and which may be too incomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83a8ffd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "09a4ccfb-8e80-4576-858d-3d63f0ea1352",
       "rows": [
        [
         "Power (watts)",
         "6983"
        ],
        [
         " Dry Mass (kg.) ",
         "6795"
        ],
        [
         "Detailed Purpose",
         "6308"
        ],
        [
         "Expected Lifetime (yrs.)",
         "2112"
        ],
        [
         "Type of Orbit",
         "653"
        ],
        [
         "Launch Mass (kg.)",
         "247"
        ],
        [
         "Period (minutes)",
         "58"
        ],
        [
         "Eccentricity",
         "13"
        ],
        [
         "Apogee (km)",
         "9"
        ],
        [
         "Perigee (km)",
         "9"
        ],
        [
         "Inclination (degrees)",
         "6"
        ],
        [
         "Longitude of GEO (degrees)",
         "5"
        ],
        [
         "Country/Org of UN Registry",
         "3"
        ],
        [
         "Date of Launch",
         "3"
        ],
        [
         "Contractor",
         "2"
        ],
        [
         "Country of Contractor",
         "2"
        ],
        [
         "Launch Site",
         "2"
        ],
        [
         "Launch Vehicle",
         "2"
        ],
        [
         "COSPAR Number",
         "2"
        ],
        [
         "Current Official Name of Satellite",
         "2"
        ],
        [
         "Class of Orbit",
         "2"
        ],
        [
         "Purpose",
         "2"
        ],
        [
         "Users",
         "2"
        ],
        [
         "Operator/Owner",
         "2"
        ],
        [
         "Country of Operator/Owner",
         "2"
        ],
        [
         "NORAD Number",
         "2"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 26
       }
      },
      "text/plain": [
       "Power (watts)                         6983\n",
       " Dry Mass (kg.)                       6795\n",
       "Detailed Purpose                      6308\n",
       "Expected Lifetime (yrs.)              2112\n",
       "Type of Orbit                          653\n",
       "Launch Mass (kg.)                      247\n",
       "Period (minutes)                        58\n",
       "Eccentricity                            13\n",
       "Apogee (km)                              9\n",
       "Perigee (km)                             9\n",
       "Inclination (degrees)                    6\n",
       "Longitude of GEO (degrees)               5\n",
       "Country/Org of UN Registry               3\n",
       "Date of Launch                           3\n",
       "Contractor                               2\n",
       "Country of Contractor                    2\n",
       "Launch Site                              2\n",
       "Launch Vehicle                           2\n",
       "COSPAR Number                            2\n",
       "Current Official Name of Satellite       2\n",
       "Class of Orbit                           2\n",
       "Purpose                                  2\n",
       "Users                                    2\n",
       "Operator/Owner                           2\n",
       "Country of Operator/Owner                2\n",
       "NORAD Number                             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = df.isna().sum() # map column name to count of null values\n",
    "missing_values.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3e69e",
   "metadata": {},
   "source": [
    "Let's look at that as a percentage to make the comparison easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ded11b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "06817ba1-2543-424a-be31-e868fa18522e",
       "rows": [
        [
         "Power (watts)",
         "92.3%"
        ],
        [
         " Dry Mass (kg.) ",
         "89.9%"
        ],
        [
         "Detailed Purpose",
         "83.4%"
        ],
        [
         "Expected Lifetime (yrs.)",
         "27.9%"
        ],
        [
         "Type of Orbit",
         "8.6%"
        ],
        [
         "Launch Mass (kg.)",
         "3.3%"
        ],
        [
         "Period (minutes)",
         "0.8%"
        ],
        [
         "Eccentricity",
         "0.2%"
        ],
        [
         "Apogee (km)",
         "0.1%"
        ],
        [
         "Perigee (km)",
         "0.1%"
        ],
        [
         "Inclination (degrees)",
         "0.1%"
        ],
        [
         "Longitude of GEO (degrees)",
         "0.1%"
        ],
        [
         "Country/Org of UN Registry",
         "0.0%"
        ],
        [
         "Date of Launch",
         "0.0%"
        ],
        [
         "Contractor",
         "0.0%"
        ],
        [
         "Country of Contractor",
         "0.0%"
        ],
        [
         "Launch Site",
         "0.0%"
        ],
        [
         "Launch Vehicle",
         "0.0%"
        ],
        [
         "COSPAR Number",
         "0.0%"
        ],
        [
         "Current Official Name of Satellite",
         "0.0%"
        ],
        [
         "Class of Orbit",
         "0.0%"
        ],
        [
         "Purpose",
         "0.0%"
        ],
        [
         "Users",
         "0.0%"
        ],
        [
         "Operator/Owner",
         "0.0%"
        ],
        [
         "Country of Operator/Owner",
         "0.0%"
        ],
        [
         "NORAD Number",
         "0.0%"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 26
       }
      },
      "text/plain": [
       "Power (watts)                         92.3%\n",
       " Dry Mass (kg.)                       89.9%\n",
       "Detailed Purpose                      83.4%\n",
       "Expected Lifetime (yrs.)              27.9%\n",
       "Type of Orbit                          8.6%\n",
       "Launch Mass (kg.)                      3.3%\n",
       "Period (minutes)                       0.8%\n",
       "Eccentricity                           0.2%\n",
       "Apogee (km)                            0.1%\n",
       "Perigee (km)                           0.1%\n",
       "Inclination (degrees)                  0.1%\n",
       "Longitude of GEO (degrees)             0.1%\n",
       "Country/Org of UN Registry             0.0%\n",
       "Date of Launch                         0.0%\n",
       "Contractor                             0.0%\n",
       "Country of Contractor                  0.0%\n",
       "Launch Site                            0.0%\n",
       "Launch Vehicle                         0.0%\n",
       "COSPAR Number                          0.0%\n",
       "Current Official Name of Satellite     0.0%\n",
       "Class of Orbit                         0.0%\n",
       "Purpose                                0.0%\n",
       "Users                                  0.0%\n",
       "Operator/Owner                         0.0%\n",
       "Country of Operator/Owner              0.0%\n",
       "NORAD Number                           0.0%\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percent = (missing_values / total_rows) * 100\n",
    "missing_percent_sorted = missing_percent.sort_values(ascending=False)\n",
    "missing_percent_sorted.map(lambda x: f\"{x:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2ccc4",
   "metadata": {},
   "source": [
    "If a column is missing data in 25% or more of the total rows, we will exclude it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f7117b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 4 columns: Detailed Purpose,  Dry Mass (kg.) , Power (watts), Expected Lifetime (yrs.)\n"
     ]
    }
   ],
   "source": [
    "missing_threshold = total_rows // 4\n",
    "\n",
    "columns_to_exclude = missing_values[missing_values >= missing_threshold].index.tolist() # indexed on column name\n",
    "df = df.drop(columns=columns_to_exclude) # 1-dimensional array is a Series in Pandas.\n",
    "print(f\"Dropped {len(columns_to_exclude)} columns: {(', '.join(columns_to_exclude))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7008e3",
   "metadata": {},
   "source": [
    "We're almost done with the column cleanup. As a final touch, let's rename some of the more verbose columns. We'll also drop any units of measure contained in the column names (such as km)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba7e086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satellite\n",
      "UN Registry\n",
      "Country of Operator\n",
      "Operator\n",
      "Users\n",
      "Purpose\n",
      "Class of Orbit\n",
      "Type of Orbit\n",
      "Longitude of GEO\n",
      "Perigee\n",
      "Apogee\n",
      "Eccentricity\n",
      "Inclination\n",
      "Period\n",
      "Launch Mass\n",
      "Date of Launch\n",
      "Contractor\n",
      "Country of Contractor\n",
      "Launch Site\n",
      "Launch Vehicle\n",
      "COSPAR Number\n",
      "NORAD Number\n"
     ]
    }
   ],
   "source": [
    "column_renames = {\n",
    "    \"Current Official Name of Satellite\": \"Satellite\",\n",
    "    \"Country/Org of UN Registry\": \"UN Registry\",\n",
    "    \"Country of Operator/Owner\": \"Country of Operator\",\n",
    "    \"Operator/Owner\": \"Operator\"\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_renames)\n",
    "\n",
    "df.columns = (\n",
    "    df.columns\n",
    "        .str.replace(r\"\\s*\\(.*?\\)\", \"\", regex=True)\n",
    "        .str.strip()\n",
    ")\n",
    "\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f76024d",
   "metadata": {},
   "source": [
    "#### Rows\n",
    "We can tolerate missing data in certain fields, but others are essential for the analysis. If any rows have data missing data in these fields, they will either need to be dropped entirely or fixed. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43671ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date of Launch",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Launch Site",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Satellite",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "b542fc84-5f40-4cb5-9389-5fa2efbd129b",
       "rows": [
        [
         "240",
         null,
         "Rocket Lab Launch Complex 1",
         "BlackSky Global 5"
        ],
        [
         "7560",
         null,
         null,
         null
        ],
        [
         "7561",
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date of Launch</th>\n",
       "      <th>Launch Site</th>\n",
       "      <th>Satellite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Rocket Lab Launch Complex 1</td>\n",
       "      <td>BlackSky Global 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7560</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date of Launch                  Launch Site          Satellite\n",
       "240             NaN  Rocket Lab Launch Complex 1  BlackSky Global 5\n",
       "7560            NaN                          NaN                NaN\n",
       "7561            NaN                          NaN                NaN"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_columns = [\n",
    "    \"Date of Launch\",\n",
    "    \"Launch Site\",\n",
    "    \"Satellite\"\n",
    "]\n",
    "\n",
    "rows_missing_required = df[\n",
    "    df[required_columns].isna().any(axis=1)\n",
    "][required_columns]\n",
    "\n",
    "rows_missing_required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa24432",
   "metadata": {},
   "source": [
    "The satellite **BlackSky Global 5** is missing a launch date. However, this [information](https://space.oscar.wmo.int/satellites/view/blacksky_5) isn't too hard to find so let's just manually add it in: August 7, 2020.\n",
    "\n",
    "The other two rows are just blanks beyond redemption, so let's delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3140b3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 out of 7562 rows.\n",
      "Remaining rows: 7560\n"
     ]
    }
   ],
   "source": [
    "rows_before = len(df)\n",
    "\n",
    "df.loc[\n",
    "    df[\"Satellite\"] == \"BlackSky Global 5\",\n",
    "    \"Date of Launch\"\n",
    "] = \"2020-08-07\"\n",
    "\n",
    "rows_missing_required = df[\n",
    "    df[required_columns].isna().any(axis=1)\n",
    "]\n",
    "\n",
    "df = df.drop(index=rows_missing_required.index)\n",
    "\n",
    "rows_after = len(df)\n",
    "rows_removed = rows_before - rows_after\n",
    "\n",
    "print(f\"Dropped {rows_removed} out of {rows_before} rows.\")\n",
    "print(f\"Remaining rows: {rows_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2c3579",
   "metadata": {},
   "source": [
    "Many of the text columns contain extra information in parenthesis. Let's look at the `Satellite` column as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_parens = (\n",
    "    df[\"Satellite\"]\n",
    "        .astype(str)\n",
    "        .str.contains(r\"\\(\", na=False)\n",
    ")\n",
    "\n",
    "df.loc[mask_parens, [\"Satellite\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec8fa9e",
   "metadata": {},
   "source": [
    "We'll just clean house and remove these parenthetical notes and trim whitespace while we're at it. We'll do this for all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b38723",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "for col in text_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "            .str.replace(r\"\\s*\\(.*?\\)\", \"\", regex=True)\n",
    "            .str.strip()\n",
    "            .replace({\"\": pd.NA})\n",
    "    )\n",
    "\n",
    "df.loc[mask_parens, [\"Satellite\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df33434",
   "metadata": {},
   "source": [
    "### Making Booleans\n",
    "#### `Users`\n",
    "\n",
    "Now that we've got the basic dataset cleaned up, we'll take a look at some of the specific columns.\n",
    "\n",
    "`Users` contains combinations of one to four possible values separated by a \"/\", representing who is using the Satellite: *Civil*, *Commercial*, *Government*, or *Military*. This format is easy enough for a human to read in a table, but a one-to-many relationship like this will be complicated to filter in a BI tool like QuickSight or Tableau. Instead, let's make life easier by creating some boolean columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_categories = [\"Civil\", \"Commercial\", \"Government\", \"Military\"]\n",
    "\n",
    "for category in user_categories:\n",
    "    df[f\"User: Is {category}\"] = (\n",
    "        df[\"Users\"]\n",
    "            .str.contains(category, case=False, na=False)\n",
    "    )\n",
    "\n",
    "user_flag_columns = [\"User: Is Civil\", \"User: Is Commercial\", \"User: Is Government\", \"User: Is Military\"]\n",
    "\n",
    "df[user_flag_columns].sum()\n",
    "\n",
    "example_columns = [\n",
    "    \"Satellite\",\n",
    "    \"Users\",\n",
    "    \"User: Is Civil\",\n",
    "    \"User: Is Commercial\",\n",
    "    \"User: Is Government\",\n",
    "    \"User: Is Military\"\n",
    "]\n",
    "\n",
    "df[\n",
    "    df[user_flag_columns].sum(axis=1) > 1\n",
    "][example_columns].head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdafed30",
   "metadata": {},
   "source": [
    "#### `Purpose`\n",
    "\n",
    "We'll do the same thing for `Purpose`. However, here there are a few more categories. If we make bools for everything, this could get clunky. As an intermediate step though, it works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a83be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "purpose_categories = [\n",
    "    \"Communications\",\n",
    "    \"Earth Observation\",\n",
    "    \"Earth Science\",\n",
    "    \"Educational\",\n",
    "    \"Meteorological\",\n",
    "    \"Mission Extension Technology\",\n",
    "    \"Navigation\",\n",
    "    \"Platform\",\n",
    "    \"Satellite Positioning\",\n",
    "    \"Space Observation\",\n",
    "    \"Space Science\",\n",
    "    \"Surveillance\",\n",
    "    \"Technology Demonstration\",\n",
    "    \"Technology Development\",\n",
    "    \"Unknown\",\n",
    "    \"Maritime Tracking\"\n",
    "]\n",
    "\n",
    "for category in purpose_categories:\n",
    "    df[f\"Is Purpose: {category}\"] = (\n",
    "        df[\"Purpose\"]\n",
    "            .str.contains(category, case=False, na=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b43e94",
   "metadata": {},
   "source": [
    "The count by category varies significantly. Some have thousands while others only several."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f7b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose_flag_cols = [f\"Is Purpose: {c}\" for c in purpose_categories]\n",
    "\n",
    "df[purpose_flag_cols].sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7db937",
   "metadata": {},
   "source": [
    "In a lopsided situation like this, booleans become less effective. Let's consolidate some of these categories for better clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_comm = \"Is Purpose: Communications\"\n",
    "p_earth_obs = \"Is Purpose: Earth Observation\"\n",
    "p_earth_sci = \"Is Purpose: Earth Science\"\n",
    "p_edu = \"Is Purpose: Educational\"\n",
    "p_met = \"Is Purpose: Meteorological\"\n",
    "p_mext = \"Is Purpose: Mission Extension Technology\"\n",
    "p_nav = \"Is Purpose: Navigation\"\n",
    "p_platform = \"Is Purpose: Platform\"\n",
    "p_satpos = \"Is Purpose: Satellite Positioning\"\n",
    "p_space_obs = \"Is Purpose: Space Observation\"\n",
    "p_space_sci = \"Is Purpose: Space Science\"\n",
    "p_surv = \"Is Purpose: Surveillance\"\n",
    "p_tech_demo = \"Is Purpose: Technology Demonstration\"\n",
    "p_tech_dev = \"Is Purpose: Technology Development\"\n",
    "p_unknown = \"Is Purpose: Unknown\"\n",
    "p_mar = \"Is Purpose: Maritime Tracking\"\n",
    "\n",
    "\n",
    "df[\"Purpose: Communications\"] = df[p_comm]\n",
    "\n",
    "df[\"Purpose: Earth Observation\"] = (\n",
    "    df[p_earth_obs]\n",
    "    | df[p_met]\n",
    "    | df[p_surv]\n",
    "    | df[p_earth_sci]\n",
    "    | df[p_mar]\n",
    ")\n",
    "\n",
    "df[\"Purpose: Navigation\"] = (\n",
    "    df[p_nav]\n",
    "    | df[p_satpos]\n",
    ")\n",
    "\n",
    "df[\"Purpose: Space Science\"] = (\n",
    "    df[p_space_sci]\n",
    "    | df[p_space_obs]\n",
    ")\n",
    "\n",
    "df[\"Purpose: Tech Dev\"] = (\n",
    "    df[p_tech_dev]\n",
    "    | df[p_edu] \n",
    "    | df[p_platform] \n",
    "    | df[p_tech_demo]\n",
    "    | df[p_mext]\n",
    ")\n",
    "\n",
    "df[\"Purpose: Unknown\"] = df[p_unknown]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cafb043",
   "metadata": {},
   "source": [
    "This gets us down to six `Purpose` boolean columns which will be much more manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf84edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_cols = [\n",
    "    \"Purpose: Communications\",\n",
    "    \"Purpose: Earth Observation\",\n",
    "    \"Purpose: Navigation\",\n",
    "    \"Purpose: Space Science\",\n",
    "    \"Purpose: Tech Dev\",\n",
    "    \"Purpose: Unknown\",\n",
    "]\n",
    "\n",
    "original_purpose_flag_cols = [c for c in df.columns if c.startswith(\"Is Purpose: \")]\n",
    "df = df.drop(columns=original_purpose_flag_cols)\n",
    "\n",
    "df[consolidated_cols].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2235c26",
   "metadata": {},
   "source": [
    "### Aggregating\n",
    "#### `Type of Orbit` and `Class of Orbit`\n",
    "\n",
    "Next let's take a look the type of orbit. Unlike `Users` or `Purpose`, `Type of Orbit` is a 1:1 relationship. A satellite will only have a single type of orbit. However, this also looks like it could benefit from some consolidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081baf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_counts = (\n",
    "    df[\"Type of Orbit\"]\n",
    "        .value_counts()\n",
    "        .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "orbit_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e5bfd6",
   "metadata": {},
   "source": [
    "Since some of these orbits could be considered [subtypes](https://en.wikipedia.org/wiki/Orbit), we'll aggregate them into six larger categories. The new column we will consider to be the broader `Orbit Category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7abf904",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_mapping = {\n",
    "    \"Non-Polar Inclined\": \"Inclined\",\n",
    "    \"Sun-Synchronous\": \"Sun-Synchronous\",\n",
    "    \"Sun-Synchronous near polar\": \"Sun-Synchronous\",\n",
    "    \"Polar\": \"Polar\",\n",
    "    \"Equatorial\": \"Equatorial\",\n",
    "    \"Molniya\": \"Highly Elliptical\",\n",
    "    \"Deep Highly Eccentric\": \"Highly Elliptical\",\n",
    "    \"Elliptical\": \"Highly Elliptical\",\n",
    "    \"Retrograde\": \"Other\",\n",
    "    \"Cislunar\": \"Other\",\n",
    "}\n",
    "\n",
    "df[\"Orbit Category\"] = (\n",
    "    df[\"Type of Orbit\"].map(orbit_mapping) # map replaces one value with another\n",
    ")\n",
    "\n",
    "df[\"Orbit Category\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0dee9",
   "metadata": {},
   "source": [
    "The `Class of Orbit` refers to the altitude of the orbit. The original dataset is divided into two broad classes: \n",
    "* *nearly circular orbits*: LEO, MEO, and GEO\n",
    "* *elliptical orbits*\n",
    "Satellites in elliptical orbits have apogees and perigees that differ significantly from each other. They spend time at many different altitudes above the earthâ€™s surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class of Orbit\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754a434",
   "metadata": {},
   "source": [
    "However, for the purposes of our analysis, we'll consider elliptical orbits to be *High Earth Orbits (HEO)* based on the apogee. This will avoid confusion the category in `Type of Orbit`. We'll also clean up the capitalization type for Low Earth Orbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"Class of Orbit\"] = (\n",
    "    df[\"Class of Orbit\"]\n",
    "        .replace({\n",
    "            \"LEo\": \"LEO\",\n",
    "            \"Elliptical\": \"HEO\"\n",
    "        })\n",
    ")\n",
    "\n",
    "df[\"Class of Orbit\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc37f6",
   "metadata": {},
   "source": [
    "Since the shape of the orbit is still relevant though, we'll derive this from `Class of Orbit` and capture this in a new field: `Shape of Orbit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551cfa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Shape of Orbit\"] = (\n",
    "    df[\"Class of Orbit\"]\n",
    "        .map({\n",
    "            \"LEO\": \"Circular\",\n",
    "            \"MEO\": \"Circular\",\n",
    "            \"GEO\": \"Circular\",\n",
    "            \"HEO\": \"Elliptical\",\n",
    "        })\n",
    ")\n",
    "\n",
    "df[\"Shape of Orbit\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545897db",
   "metadata": {},
   "source": [
    "Now that we've got three fields of orbit data, let's do another rename so they are easier to find later in our BI tool. We'll make sure everything starts with *Orbit*. We'll also rename `Type of Orbit` to `Orbit Subcategory` to be better reflect the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    \"Type of Orbit\": \"Orbit Subcategory\",\n",
    "    \"Class of Orbit\": \"Orbit Class\",\n",
    "    \"Shape of Orbit\": \"Orbit Shape\",\n",
    "})\n",
    "\n",
    "[c for c in df.columns if \"Orbit\" in c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de9cb01",
   "metadata": {},
   "source": [
    "### Mapping and Normalizing\n",
    "#### `Operator` and `Contractor`\n",
    "\n",
    "Here's where things get messy. The fields of `Operator` and `Contractor` were manually entered and cover a wide variety of organizations. As a result, several distinct issues appear:\n",
    "\n",
    "* **Minor formatting and naming variations**: The same organization may appear multiple times due to differences in capitalization, punctuation, spacing, or legal suffixes\n",
    "\n",
    "* **Parent companies vs. subsidiaries or internal divisions**: Some organizations are listed as specific subsidiaries, regional branches, or internal divisions of a larger organization\n",
    "\n",
    "* **Joint or multi-organization missions**: Certain satellites are operated jointly by multiple organizations and are recorded as a combined value\n",
    "\n",
    "* **Mixed organization types**: This includes private companies, government agencies, military organizations, universities, and research institutions that do not easily fit into a single hierarchy\n",
    "\n",
    "For our purposes, granular distinction is beyond the scope of this project. We will do what we can do simplify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6cfae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_sample = (\n",
    "    pd.Series(df[\"Operator\"].dropna().unique())\n",
    "      .sample(5, random_state=42)\n",
    "      .tolist()\n",
    ")\n",
    "\n",
    "total_op_begin = df[\"Operator\"].nunique()\n",
    "total_con_begin = df[\"Contractor\"].nunique()\n",
    "\n",
    "print(f\"Operators: {total_op_begin}\")\n",
    "print(f\"Contractors: {total_con_begin}\")\n",
    "print(f\"Sample: {', '.join(op_sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df80cae",
   "metadata": {},
   "source": [
    "That's a fairly large amount to clean up. To begin, let's see what we can do with fixing the formatting. We'll remove suffices, trim whitespace, and apply other normalization standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_org_column(df, col_name):\n",
    "    s = (\n",
    "        df[col_name]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.replace(r\"\\s+\", \" \", regex=True)                 # collapse multiple spaces\n",
    "            .str.replace(r\"\\s*/\\s*\", \"/\", regex=True)             # normalize slash spacing\n",
    "            .str.replace(r\",\", \"\", regex=True)                    # remove commas\n",
    "            .str.replace(r\"\\s+\\.\", \".\", regex=True)               # remove space before period\n",
    "            .str.replace(r\"\\.$\", \"\", regex=True)                  # drop trailing periods\n",
    "            .str.replace(\n",
    "                r\"\\b(Ltd|Inc|LLC|PLC|Corp|Corporation|Co|S A|SA)\\b\",\n",
    "                \"\",\n",
    "                regex=True\n",
    "            )                                                     # drop common suffixes\n",
    "            .str.replace(r\"\\s+\", \" \", regex=True)                 # re-collapse spaces\n",
    "            .str.strip()\n",
    "            .replace({\"nan\": pd.NA})\n",
    "    )\n",
    "    \n",
    "    s = s.str.split(\"/\").str[0].str.strip() # Keep first entry\n",
    "\n",
    "    df[col_name] = s\n",
    "    return df[col_name]\n",
    "\n",
    "normalize_org_column(df, \"Operator\")\n",
    "normalize_org_column(df, \"Contractor\")\n",
    "\n",
    "op_sample_2 = (\n",
    "    pd.Series(df[\"Operator\"].dropna().unique())\n",
    "      .sample(5, random_state=42)\n",
    "      .tolist()\n",
    ")\n",
    "\n",
    "total_op_begin_2 = df[\"Operator\"].nunique()\n",
    "total_con_begin_2 = df[\"Contractor\"].nunique()\n",
    "\n",
    "print(f\"Operators: {total_op_begin_2} (consolidated {total_op_begin - total_op_begin_2})\")\n",
    "print(f\"Contractors: {total_con_begin_2} (consolidated {total_con_begin - total_con_begin_2})\")\n",
    "print(f\"Sample: {', '.join(op_sample_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d39b14",
   "metadata": {},
   "source": [
    "From trial and error, I found that universities were particularly challenging to cleanup. Here are some functions specific for academic institutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da9a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_university_cleanup(s: str):\n",
    "    if s is None or pd.isna(s):\n",
    "        return s\n",
    "\n",
    "    s = str(s).strip()\n",
    "\n",
    "    if \"University\" not in s:\n",
    "        return s\n",
    "\n",
    "    m = re.search(r\"\\bUniversity\\b.*\", s) # Grab from the first \"University\" onward\n",
    "    if not m:\n",
    "        return s\n",
    "\n",
    "    uni_part = m.group(0)\n",
    "    uni_part = re.split(r\"[,/]\", uni_part, maxsplit=1)[0].strip()\n",
    "\n",
    "    if uni_part.lower() == \"university\": # Never collapse to just \"University\"\n",
    "        return s\n",
    "\n",
    "    return uni_part\n",
    "\n",
    "\n",
    "def strip_trailing_space_and_punct(series: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        series\n",
    "            .astype(\"string\")\n",
    "            .str.replace(r\"[\\s\\.\\,\\;\\:\\-]+$\", \"\", regex=True)\n",
    "            .str.strip()\n",
    "            .replace({\"nan\": pd.NA})\n",
    "    )\n",
    "\n",
    "\n",
    "def apply_academic_and_trailing_cleanup(df, col_name):\n",
    "    df[col_name] = df[col_name].apply(safe_university_cleanup)\n",
    "    df[col_name] = strip_trailing_space_and_punct(df[col_name])\n",
    "    return df[col_name]\n",
    "\n",
    "apply_academic_and_trailing_cleanup(df, \"Operator\")\n",
    "apply_academic_and_trailing_cleanup(df, \"Contractor\")\n",
    "\n",
    "total_op_begin_3 = df[\"Operator\"].nunique()\n",
    "total_con_begin_3 = df[\"Contractor\"].nunique()\n",
    "\n",
    "print(f\"Operators: {total_op_begin_3} (consolidated {total_op_begin_2 - total_op_begin_3})\")\n",
    "print(f\"Contractors: {total_con_begin_3} (consolidated {total_con_begin_2 - total_con_begin_3})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a954b3f7",
   "metadata": {},
   "source": [
    "Now that the basic cleanup is done, on to the big step: mapping. Since there are over 300 organizations that need mapping, I've put these into a separate JSON we'll be loading in. Identifying the corrections took a fairly substantial amount of manual effort and required some judgement calls as well. This task would be a good candidate for ML, but that's beyond the scope of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fe32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/op_con_mapping.json\", \"r\") as f:\n",
    "    op_con_mapping = json.load(f)\n",
    "\n",
    "def apply_canonical_mapping(df, col_name: str, mapping: dict):\n",
    "\n",
    "    df[col_name] = df[col_name].map(mapping).fillna(df[col_name]) # Fallback to existing name\n",
    "    df[col_name] = df[col_name].fillna(\"Unknown\") # fill missing with \"Unknown\"\n",
    "\n",
    "    return df[col_name]\n",
    "\n",
    "apply_canonical_mapping(df, \"Operator\", op_con_mapping)\n",
    "apply_canonical_mapping(df, \"Contractor\", op_con_mapping)\n",
    "\n",
    "total_op_begin_4 = df[\"Operator\"].nunique()\n",
    "total_con_begin_4 = df[\"Contractor\"].nunique()\n",
    "\n",
    "print(f\"Operators: {total_op_begin_4} (consolidated {total_op_begin_3 - total_op_begin_4})\")\n",
    "print(f\"Contractors: {total_con_begin_4} (consolidated {total_con_begin_3 - total_con_begin_4})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0826608",
   "metadata": {},
   "source": [
    "That narrows it down a bit. Let's take a peak at the Top 10 most common Operators and Contractors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 Operators:\")\n",
    "display(df[\"Operator\"].value_counts().head(10))\n",
    "\n",
    "print(\"Top 10 Contractors:\")\n",
    "display(df[\"Contractor\"].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600475a7",
   "metadata": {},
   "source": [
    "#### `Launch Vehicle`\n",
    "\n",
    "There's a lot more crammed into this field than the name suggests. Some are actual launch vehicles while other include (or substitute) the launch method, the booster stage, or the spacecraft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_count = df[\"Launch Vehicle\"].nunique()\n",
    "\n",
    "lv_sample = (\n",
    "    pd.Series(df[\"Launch Vehicle\"].dropna().unique())\n",
    "      .sample(5, random_state=42)\n",
    "      .tolist()\n",
    ")\n",
    "\n",
    "print(f\"Launch Vehicles: {lv_count}\")\n",
    "print(f\"Sample: {', '.join(lv_sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e7bb85",
   "metadata": {},
   "source": [
    "We'll begin by deriving the `Launch Vehicle Family`. This is the high-level rocket family for grouping and charts. We'll also make note of alternative methods for a later calculation.\n",
    "\n",
    "Instead of using a dictionary, since the launch vehicles are more standardized, we'll use a substring search to do the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_launch_vehicle_family(lv):\n",
    "    if pd.isna(lv):\n",
    "        return \"Unknown\"\n",
    "\n",
    "    lv = lv.strip()\n",
    "\n",
    "    if \"Nanorack\" in lv:\n",
    "        return \"Nanorack\"\n",
    "    if \"Slingshot\" in lv or \"Dispenser\" in lv:\n",
    "        return \"Deployer\"\n",
    "\n",
    "    if lv in {\"L1011\", \"LauncherOne\"}:\n",
    "        return \"Air Launch\"\n",
    "\n",
    "    if lv == \"Space Shuttle\":\n",
    "        return \"Space Shuttle\"\n",
    "\n",
    "    # Rocket families\n",
    "    if lv.startswith(\"Falcon\"):\n",
    "        return \"Falcon\"\n",
    "    if lv.startswith(\"Atlas\"):\n",
    "        return \"Atlas\"\n",
    "    if lv.startswith(\"Soyuz\"):\n",
    "        return \"Soyuz\"\n",
    "    if lv.startswith(\"Ariane\"):\n",
    "        return \"Ariane\"\n",
    "    if lv.startswith(\"Long March\"):\n",
    "        return \"Long March\"\n",
    "    if lv.startswith(\"PSLV\"):\n",
    "        return \"PSLV\"\n",
    "    if lv.startswith(\"GSLV\") or lv.startswith(\"LVM3\"):\n",
    "        return \"GSLV\"\n",
    "    if lv.startswith(\"SSLV\"):\n",
    "        return \"SSLV\"\n",
    "    if lv.startswith(\"Delta\"):\n",
    "        return \"Delta\"\n",
    "    if lv.startswith(\"Titan\"):\n",
    "        return \"Titan\"\n",
    "    if lv.startswith(\"Zenit\"):\n",
    "        return \"Zenit\"\n",
    "    if lv.startswith(\"Minotaur\"):\n",
    "        return \"Minotaur\"\n",
    "    if lv.startswith(\"Electron\"):\n",
    "        return \"Electron\"\n",
    "    if lv.startswith(\"Antares\"):\n",
    "        return \"Antares\"\n",
    "    if lv.startswith(\"Vega\"):\n",
    "        return \"Vega\"\n",
    "    if lv.startswith(\"Pegasus\"):\n",
    "        return \"Pegasus\"\n",
    "    if lv.startswith(\"Taurus\"):\n",
    "        return \"Taurus\"\n",
    "    if lv.startswith(\"Proton\"):\n",
    "        return \"Proton\"\n",
    "    if lv.startswith(\"Dnepr\"):\n",
    "        return \"Dnepr\"\n",
    "    if lv.startswith(\"Nuri\"):\n",
    "        return \"Nuri\"\n",
    "    if lv.startswith(\"Shavit\"):\n",
    "        return \"Shavit\"\n",
    "    if lv.startswith(\"H2\"):\n",
    "        return \"H-II\"\n",
    "    if lv.startswith(\"Kuaizhou\"):\n",
    "        return \"Kuaizhou\"\n",
    "    if lv.startswith(\"Ceres\"):\n",
    "        return \"Ceres\"\n",
    "    if lv.startswith(\"Rokot\"):\n",
    "        return \"Rokot\"\n",
    "    if lv.startswith(\"Start\"):\n",
    "        return \"Start\"\n",
    "    if lv.startswith(\"Qased\"):\n",
    "        return \"Qased\"\n",
    "    if lv.startswith(\"Naro\"):\n",
    "        return \"Naro\"\n",
    "    if lv.startswith(\"Jielong\"):\n",
    "        return \"Jielong\"\n",
    "    if lv.startswith(\"Tsyklon\"):\n",
    "        return \"Tsyklon\"\n",
    "    if lv.startswith(\"Rocket 3\"):\n",
    "        return \"Rocket 3\"\n",
    "    if lv.startswith(\"Kosmos\"):\n",
    "        return \"Kosmos\"\n",
    "    if lv.startswith(\"Epsilon\"):\n",
    "        return \"Epsilon\"\n",
    "    if lv.startswith(\"JAXA M\"):\n",
    "        return \"JAXA M-V\"\n",
    "    if lv.startswith(\"KT-\"):\n",
    "        return \"KT-2\"\n",
    "\n",
    "    return \"Other\"\n",
    "\n",
    "df[\"Launch Vehicle Family\"] = df[\"Launch Vehicle\"].apply(get_launch_vehicle_family)\n",
    "df[\"Launch Vehicle Family\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4482aec3",
   "metadata": {},
   "source": [
    "Next, we'll explore the `Launch Method` to look at how the satellite reached orbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_launch_method(lv):\n",
    "    if pd.isna(lv):\n",
    "        return \"Unknown\"\n",
    "\n",
    "    if \"Deployer\" in lv or \"Dispenser\" in lv or \"Slingshot\" in lv:\n",
    "        return \"Deployer / Hosted Payload\"\n",
    "\n",
    "    if lv in {\"L1011\", \"LauncherOne\"}:\n",
    "        return \"Air Launch\"\n",
    "\n",
    "    if lv == \"Space Shuttle\":\n",
    "        return \"Space Shuttle\"\n",
    "\n",
    "    return \"Orbital Rocket\"\n",
    "\n",
    "df[\"Launch Method\"] = df[\"Launch Vehicle\"].apply(get_launch_method)\n",
    "df[\"Launch Method\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78945f",
   "metadata": {},
   "source": [
    "Since our mapping was just based on substrings, it's entirely possible that our initial pass missed some categorizations. Let's see if we can find any such anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a42303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    df[\"Launch Vehicle Family\"].isin([\"Other\", \"Deployer\"])\n",
    "][[\"Launch Vehicle\", \"Launch Vehicle Family\", \"Launch Method\"]].head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a0944",
   "metadata": {},
   "source": [
    "The *Other* category seems like it could benefit from further cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_lv = df[\n",
    "    df[\"Launch Vehicle Family\"] == \"Other\"\n",
    "][\"Launch Vehicle\"]\n",
    "\n",
    "print(f\"Total records classified as 'Other': {len(other_lv)}\")\n",
    "print(f\"\\nLaunch Vehicle values classified as 'Other' (with counts):\")\n",
    "\n",
    "other_lv.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff392e",
   "metadata": {},
   "source": [
    "We'll do another cleanup pass to reclassify \"Other\" launch vehicle families. Some values classified as \"Other\" are not actually launch vehicles such as upper stages or spacecraft. Since the atual launch vehicle wasn't provided, we can more accurately classify these as \"Unknown\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3819840",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_launch_vehicle_values = {\n",
    "    \"Breeze M\",\n",
    "    \"Breeze KM\",\n",
    "    \"Cygnus\",\n",
    "    \"Fa\",\n",
    "}\n",
    "\n",
    "mask_invalid_other = (\n",
    "    (df[\"Launch Vehicle Family\"] == \"Other\") &\n",
    "    (df[\"Launch Vehicle\"].isin(invalid_launch_vehicle_values))\n",
    ")\n",
    "\n",
    "df.loc[mask_invalid_other, \"Launch Vehicle Family\"] = \"Unknown\"\n",
    "\n",
    "df[\"Launch Vehicle Family\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4240cc",
   "metadata": {},
   "source": [
    "### Handling Dates\n",
    "#### `Date of Launch`\n",
    "\n",
    "To begin, let's see if any dates are incorrectly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e618dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_attempt = pd.to_datetime(\n",
    "    df[\"Date of Launch\"],\n",
    "    errors=\"coerce\",\n",
    "    format=\"mixed\"\n",
    ")\n",
    "\n",
    "bad_dates = df.loc[\n",
    "    parsed_attempt.isna() & df[\"Date of Launch\"].notna(),\n",
    "    [\"Satellite\", \"Date of Launch\"]\n",
    "].copy()\n",
    "\n",
    "print(\"Rows with unparseable Date of Launch values:\")\n",
    "display(bad_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46460c5e",
   "metadata": {},
   "source": [
    "We've got two. These look like basic typos so we can manually clean them up. Afterward, it'll be safe to parse the column as a datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f146fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_date_fixes = {\n",
    "    \"Cicero-8\": \"11/29/2018\",\n",
    "    \"Tianmu-1 01\": \"1/9/2023\",\n",
    "}\n",
    "\n",
    "for sat, corrected in manual_date_fixes.items():\n",
    "    df.loc[df[\"Satellite\"] == sat, \"Date of Launch\"] = corrected\n",
    "\n",
    "df[\"Date of Launch\"] = pd.to_datetime(\n",
    "    df[\"Date of Launch\"],\n",
    "    errors=\"coerce\",\n",
    "    format=\"mixed\"\n",
    ")\n",
    "\n",
    "remaining_missing = df[\"Date of Launch\"].isna().sum()\n",
    "print(f\"Remaining missing/unparseable Date of Launch values after fixes: {remaining_missing}\")\n",
    "\n",
    "display(df[df[\"Satellite\"].isin(manual_date_fixes.keys())][\n",
    "    [\"Satellite\", \"Date of Launch\"]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fccb947",
   "metadata": {},
   "source": [
    "The dataset was last updated on May 1, 2023. Let's use this date to calculate the years in orbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE_DATE = pd.Timestamp(\"2023-05-01\")\n",
    "\n",
    "launch_date = pd.to_datetime(\n",
    "    df[\"Date of Launch\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "years_in_orbit = (\n",
    "    (REFERENCE_DATE - launch_date).dt.days / 365.25\n",
    ")\n",
    "\n",
    "df[\"Years in Orbit\"] = np.floor(years_in_orbit).astype(\"Int64\")\n",
    "\n",
    "df[[\"Satellite\", \"Date of Launch\", \"Years in Orbit\"]].tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f08aa64",
   "metadata": {},
   "source": [
    "### Extrapolating Geographic Data\n",
    "#### `Launch Site`\n",
    "\n",
    "We've got launch sites, but we can use this to get a lot more geodata. To start though, the site names could use some basic cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4fb230",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_count = df[\"Launch Site\"].dropna().nunique()\n",
    "launch_sites = sorted(df[\"Launch Site\"].dropna().unique())\n",
    "\n",
    "print(f\"Launch Sites: {site_count}\")\n",
    "for i in range(0, len(launch_sites), 5):\n",
    "    print(\", \".join(launch_sites[i:i+5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8871b370",
   "metadata": {},
   "source": [
    "There's some variations on spelling (Center vs Centre) as well as some sites with additional information like the specific launch pad. We'll normalize this then also assign categorize the launch site. \n",
    "\n",
    "Specifically, we want to flag sites that are traditional spaceports since they can be flagged with geodata, as opposed to sea, air, and space-based launch platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d42914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_launch_site(site):\n",
    "    if pd.isna(site):\n",
    "        return (\"Unknown\", \"Unknown\")\n",
    "\n",
    "    s = str(site).strip()\n",
    "\n",
    "    # Space-based\n",
    "    if \"International Space Station\" in s:\n",
    "        return (\"International Space Station\", \"Space-Based\")\n",
    "\n",
    "    # Air launch\n",
    "    if s in {\"Orbital ATK L-1011\", \"Stargazer L-1011\", \"Virgin Orbit\"}:\n",
    "        return (\"Air Launch\", \"Air Launch\")\n",
    "\n",
    "    # Sea launch\n",
    "    if s in {\"Sea Launch Odyssey\", \"Yellow Sea Launch Platform\"}:\n",
    "        return (\"Sea Launch\", \"Sea Launch\")\n",
    "\n",
    "    # Clearly not a site (wrong field)\n",
    "    if s in {\"Antares\", \"Cygnus\", \"FANTM-RAiL\", \"FANTM-RAiL [Xtenti]\"}:\n",
    "        return (\"Unknown\", \"Unknown\")\n",
    "\n",
    "    # Geographic launch sites\n",
    "    site_mapping = {\n",
    "        \"Cape Canaveral\": \"Cape Canaveral Space Force Station\",\n",
    "        \"Vandeberg AFB\": \"Vandenberg Space Force Base\",\n",
    "        \"Vandenberg AFB\": \"Vandenberg Space Force Base\",\n",
    "        \"Baikonur Cosmodrome\": \"Baikonur Cosmodrome\",\n",
    "        \"Guiana Space Center\": \"Guiana Space Center\",\n",
    "        \"Jiuquan Satellite Launch Center\": \"Jiuquan Satellite Launch Center\",\n",
    "        \"Xichang Satellite Launch Center\": \"Xichang Satellite Launch Center\",\n",
    "        \"Taiyan Launch Center\": \"Taiyuan Launch Center\",\n",
    "        \"Taiyuan Launch Center\": \"Taiyuan Launch Center\",\n",
    "        \"Wenchang Satellite Launch Center\": \"Wenchang Space Center\",\n",
    "        \"Wenchang Space Center\": \"Wenchang Space Center\",\n",
    "        \"Plesetsk Cosmodrome\": \"Plesetsk Cosmodrome\",\n",
    "        \"Vostochny Cosmodrome\": \"Vostochny Cosmodrome\",\n",
    "        \"Svobodny Cosmodrome\": \"Svobodny Cosmodrome\",\n",
    "        \"Satish Dhawan Space Centre\": \"Satish Dhawan Space Center\",\n",
    "        \"Satish Dhawan Space Center\": \"Satish Dhawan Space Center\",\n",
    "        \"Tanegashima Space Center\": \"Tanegashima Space Center\",\n",
    "        \"Uchinoura Space Center\": \"Uchinoura Space Center\",\n",
    "        \"Naro Space Center\": \"Naro Space Center\",\n",
    "        \"Wallops Island Flight Facility\": \"Wallops Flight Facility\",\n",
    "        \"Mid-Atlantic Regional Spaceport/Wallops Island\": \"Wallops Flight Facility\",\n",
    "        \"Kodiak Island\": \"Pacific Spaceport Complex â€“ Alaska\",\n",
    "        \"Kodiak Launch Complex\": \"Pacific Spaceport Complex â€“ Alaska\",\n",
    "        \"Kwajalein Island\": \"Reagan Test Site (Kwajalein)\",\n",
    "        \"Shahroud Missile Range\": \"Shahroud Missile Range\",\n",
    "        \"Rocket Lab Launch Complex 1\": \"Rocket Lab Launch Complex\",\n",
    "        \"Rocket Lab Launch Complex 1B\": \"Rocket Lab Launch Complex\",\n",
    "    }\n",
    "\n",
    "    normalized = site_mapping.get(s, s)\n",
    "    return (normalized, \"Geographic\")\n",
    "\n",
    "\n",
    "# Apply normalization to create/overwrite Launch Site and Launch Site Type\n",
    "df[[\"Launch Site\", \"Launch Site Type\"]] = (\n",
    "    df[\"Launch Site\"].apply(lambda x: pd.Series(normalize_launch_site(x)))\n",
    ")\n",
    "\n",
    "# Quick check\n",
    "df[\"Launch Site Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77769c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique Launch Site values (sorted)\n",
    "for site in sorted(df[\"Launch Site\"].dropna().unique()):\n",
    "    print(repr(site))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf46497",
   "metadata": {},
   "source": [
    "With the site names normalized, now we can add geodata for the Country, Region/State, and City of the launch site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_site_geo = {\n",
    "    \"Baikonur Cosmodrome\": (\"Kazakhstan\", \"Baikonur Region\", \"Baikonur\"),\n",
    "    \"Cape Canaveral Space Force Station\": (\"United States\", \"Florida\", \"Cape Canaveral\"),\n",
    "    \"Dombarovsky Air Base\": (\"Russia\", \"Orenburg Oblast\", \"Yasny\"),\n",
    "    \"Guiana Space Center\": (\"France\", \"French Guiana\", \"Kourou\"),\n",
    "    \"Jiuquan Satellite Launch Center\": (\"China\", \"Gansu\", \"Jiuquan\"),\n",
    "    \"Naro Space Center\": (\"South Korea\", \"South Jeolla\", \"Goheung\"),\n",
    "    \"Pacific Spaceport Complex â€“ Alaska\": (\"United States\", \"Alaska\", \"Kodiak\"),\n",
    "    \"Palmachim Launch Complex\": (\"Israel\", \"Central District\", \"Palmachim\"),\n",
    "    \"Plesetsk Cosmodrome\": (\"Russia\", \"Arkhangelsk Oblast\", \"Mirny\"),\n",
    "    \"Reagan Test Site (Kwajalein)\": (\"Marshall Islands\", \"Kwajalein Atoll\", \"Kwajalein\"),\n",
    "    \"Rocket Lab Launch Complex\": (\"New Zealand\", \"Hawkeâ€™s Bay\", \"Mahia\"),\n",
    "    \"Satish Dhawan Space Center\": (\"India\", \"Andhra Pradesh\", \"Sriharikota\"),\n",
    "    \"Shahroud Missile Range\": (\"Iran\", \"Semnan Province\", \"Shahroud\"),\n",
    "    \"Svobodny Cosmodrome\": (\"Russia\", \"Amur Oblast\", \"Svobodny\"),\n",
    "    \"Taiyuan Launch Center\": (\"China\", \"Shanxi\", \"Taiyuan\"),\n",
    "    \"Tanegashima Space Center\": (\"Japan\", \"Kagoshima Prefecture\", \"Minamitane\"),\n",
    "    \"Uchinoura Space Center\": (\"Japan\", \"Kagoshima Prefecture\", \"Kimotsuki\"),\n",
    "    \"Vandenberg Space Force Base\": (\"United States\", \"California\", \"Lompoc\"),\n",
    "    \"Vostochny Cosmodrome\": (\"Russia\", \"Amur Oblast\", \"Tsiolkovsky\"),\n",
    "    \"Wallops Flight Facility\": (\"United States\", \"Virginia\", \"Wallops Island\"),\n",
    "    \"Wenchang Space Center\": (\"China\", \"Hainan\", \"Wenchang\"),\n",
    "    \"Xichang Satellite Launch Center\": (\"China\", \"Sichuan\", \"Xichang\"),\n",
    "}\n",
    "\n",
    "df[[\"Launch Country\", \"Launch Region\", \"Launch City\"]] = (\n",
    "    df[\"Launch Site\"]\n",
    "        .map(lambda s: launch_site_geo.get(s, (pd.NA, pd.NA, pd.NA)))\n",
    "        .apply(pd.Series)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7634d746",
   "metadata": {},
   "source": [
    "To confirm our geographic efforts have been successful, let's look at `Launch Site` counts for sites that have no country associated. These should only be air, sea, space, or unknown launch locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1aef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\n",
    "    df[\"Launch Country\"].isna()\n",
    "][\"Launch Site\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b0a12a",
   "metadata": {},
   "source": [
    "We can also get a sneak peak at which sites have the most launches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003cd523",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_location_counts = (\n",
    "    df\n",
    "        .groupby(\n",
    "            [\"Launch Site\", \"Launch Country\", \"Launch Region\", \"Launch City\"],\n",
    "            dropna=False\n",
    "        )\n",
    "        .size()\n",
    "        .reset_index(name=\"Count\")\n",
    "        .sort_values(\"Count\", ascending=False)\n",
    ")\n",
    "\n",
    "launch_location_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bdac35",
   "metadata": {},
   "source": [
    "Next, let's add latitude and longitude coordinates for the sites. We can use this for mapping in a visual and also use it for calculations. We'll check to make sure that all of our terrestrial sites have coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaeb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_site_coords = {\n",
    "    # Non-geographic / mobile\n",
    "    \"Air Launch\": (pd.NA, pd.NA),\n",
    "    \"Sea Launch\": (pd.NA, pd.NA),\n",
    "    \"International Space Station\": (pd.NA, pd.NA),\n",
    "    \"Unknown\": (pd.NA, pd.NA),\n",
    "\n",
    "    # French Guiana\n",
    "    \"Guiana Space Center\": (5.2360, -52.7750),\n",
    "\n",
    "    # US\n",
    "    \"Vandenberg Space Force Base\": (34.73734, -120.58431),\n",
    "    \"Wallops Flight Facility\": (37.9402, -75.4664),\n",
    "    \"Pacific Spaceport Complex â€“ Alaska\": (57.44283, -152.35811),\n",
    "    \"Cape Canaveral Space Force Station\": (28.48731, -80.57429),\n",
    "\n",
    "    # Marshall Islands\n",
    "    \"Reagan Test Site (Kwajalein)\": (8.72512, 167.72818),\n",
    "\n",
    "    # Russia / Kazakhstan\n",
    "    \"Vostochny Cosmodrome\": (51.8167, 128.2500),\n",
    "    \"Plesetsk Cosmodrome\": (62.92805, 40.57559),\n",
    "    \"Dombarovsky Air Base\": (51.09393, 59.84266),\n",
    "    \"Svobodny Cosmodrome\": (51.88888, 128.11187),\n",
    "    \"Baikonur Cosmodrome\": (45.9200, 63.3420),\n",
    "\n",
    "    # China\n",
    "    \"Jiuquan Satellite Launch Center\": (40.9546639, 100.2883333),\n",
    "    \"Taiyuan Launch Center\": (38.8427806, 111.6050972), \n",
    "    \"Xichang Satellite Launch Center\": (28.2409417, 102.0226000),  \n",
    "    \"Wenchang Space Center\": (19.6144917, 110.9511333), \n",
    "\n",
    "    # Japan\n",
    "    \"Tanegashima Space Center\": (30.40000, 130.97000), \n",
    "    \"Uchinoura Space Center\": (31.25151, 131.07549),\n",
    "\n",
    "    # India\n",
    "    \"Satish Dhawan Space Center\": (13.719939, 80.230425), \n",
    "\n",
    "    # South Korea\n",
    "    \"Naro Space Center\": (34.4319, 127.5351),\n",
    "\n",
    "    # Israel\n",
    "    \"Palmachim Launch Complex\": (31.89778, 34.69056), \n",
    "\n",
    "    # New Zealand\n",
    "    \"Rocket Lab Launch Complex\": (-39.26085, 177.86586),\n",
    "\n",
    "    # Iran\n",
    "    \"Shahroud Missile Range\": (36.20092, 55.33366),\n",
    "}\n",
    "\n",
    "df[\"Launch Latitude\"] = df[\"Launch Site\"].map(lambda s: launch_site_coords.get(s, (pd.NA, pd.NA))[0])\n",
    "df[\"Launch Longitude\"] = df[\"Launch Site\"].map(lambda s: launch_site_coords.get(s, (pd.NA, pd.NA))[1])\n",
    "\n",
    "print(\"Rows missing Launch Latitude:\", df[\"Launch Latitude\"].isna().sum())\n",
    "\n",
    "missing_sites = (\n",
    "    df.loc[df[\"Launch Latitude\"].isna(), \"Launch Site\"]\n",
    "    .value_counts()\n",
    ")\n",
    "\n",
    "print(\"\\nLaunch Sites missing coordinates (count):\")\n",
    "display(missing_sites)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b888bc",
   "metadata": {},
   "source": [
    "Now that we have the coordinates, we can use the latiitude to calculate the distance (in kilometers) from the equator and to the nearest pole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "KM_PER_DEGREE_LAT = 111.32\n",
    "\n",
    "lat_numeric = pd.to_numeric(df[\"Launch Latitude\"], errors=\"coerce\")\n",
    "\n",
    "df[\"Distance from Equator\"] = (lat_numeric.abs() * KM_PER_DEGREE_LAT).round(1)\n",
    "df[\"Distance from Pole\"] = ((90 - lat_numeric.abs()) * KM_PER_DEGREE_LAT).round(1)\n",
    "\n",
    "df[\n",
    "    df[\"Launch Latitude\"].notna()\n",
    "][\n",
    "    [\"Launch Site\", \"Launch Latitude\", \"Distance from Equator\", \"Distance from Pole\"]\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869626f",
   "metadata": {},
   "source": [
    "While we're at it, let's also classify the launch location to fit nicely into a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e464529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_launch_location(lat):\n",
    "    if pd.isna(lat):\n",
    "        return \"Unknown\"\n",
    "\n",
    "    abs_lat = abs(lat)\n",
    "\n",
    "    if abs_lat < 20:\n",
    "        return \"Close to Equator\"\n",
    "    elif abs_lat < 50:\n",
    "        return \"Mid-Latitude\"\n",
    "    else:\n",
    "        return \"Close to Pole\"\n",
    "\n",
    "\n",
    "df[\"Launch Location Category\"] = df[\"Launch Latitude\"].apply(classify_launch_location)\n",
    "\n",
    "df[\n",
    "    df[\"Launch Latitude\"].notna()\n",
    "][\n",
    "    [\"Launch Site\", \"Launch Latitude\", \"Launch Location Category\"]\n",
    "].drop_duplicates().sort_values(\"Launch Latitude\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9e980",
   "metadata": {},
   "source": [
    "Finally, let's also record the hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_hemisphere(lat):\n",
    "    if pd.isna(lat):\n",
    "        return \"Unknown\"\n",
    "    if lat > 0:\n",
    "        return \"Northern\"\n",
    "    if lat < 0:\n",
    "        return \"Southern\"\n",
    "    return \"Equator\"\n",
    "\n",
    "df[\"Hemisphere\"] = df[\"Launch Latitude\"].apply(classify_hemisphere)\n",
    "\n",
    "df[\n",
    "    df[\"Launch Latitude\"].notna()\n",
    "][[\"Launch Site\", \"Launch Latitude\", \"Distance from Equator\", \"Hemisphere\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff466f0",
   "metadata": {},
   "source": [
    "### Finishing Touches\n",
    "#### Country Names\n",
    "\n",
    "Let's finish the off with a final cleanup of country names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"UN Registry\"] = (\n",
    "    df[\"UN Registry\"]\n",
    "        .replace(r\"^\\s*$\", pd.NA, regex=True)\n",
    "        .fillna(\"Unknown\")\n",
    ")\n",
    "\n",
    "df[\"Country of Operator\"] = (\n",
    "    df[\"Country of Operator\"]\n",
    "        .astype(str)\n",
    "        .str.split(\"/\")\n",
    "        .str[0]\n",
    "        .str.strip()\n",
    "        .replace({\"Multinational\": \"Unknown\", \"nan\": pd.NA})\n",
    ")\n",
    "\n",
    "df[\"Country of Contractor\"] = (\n",
    "    df[\"Country of Contractor\"]\n",
    "        .astype(str)\n",
    "        .str.split(\"/\")\n",
    "        .str[0]\n",
    "        .str.strip()\n",
    "        .replace({\"Multinational\": \"Unknown\", \"nan\": pd.NA})\n",
    ")\n",
    "\n",
    "df[\n",
    "    [\"Country of Operator\", \"Country of Contractor\"]\n",
    "].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40cedad",
   "metadata": {},
   "source": [
    "It looks like there are some inconsistencies in using country abbreviations in the different fields. Lets standardize this. We'll also create a boolean to countries that are operators, contractors, and have the registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1eeee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_standardization = {\n",
    "    \"UK\": \"United Kingdom\",\n",
    "    \"USA\": \"United States of America\",\n",
    "}\n",
    "\n",
    "cols_to_standardize = [\"UN Registry\", \"Country of Operator\", \"Country of Contractor\"]\n",
    "\n",
    "for col in cols_to_standardize:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "            .astype(\"string\")\n",
    "            .str.strip()\n",
    "            .replace(country_standardization)\n",
    "    )\n",
    "\n",
    "df[\"Is Country Fully Consistent\"] = (\n",
    "    (df[\"UN Registry\"] == df[\"Country of Operator\"]) &\n",
    "    (df[\"Country of Operator\"] == df[\"Country of Contractor\"])\n",
    ")\n",
    "\n",
    "df[\"Is Operator/Contractor Country Match\"] = (\n",
    "    df[\"Country of Operator\"] == df[\"Country of Contractor\"]\n",
    ")\n",
    "\n",
    "df[\n",
    "    [\n",
    "        \"Satellite\",\n",
    "        \"UN Registry\",\n",
    "        \"Country of Operator\",\n",
    "        \"Country of Contractor\",\n",
    "        \"Is Country Fully Consistent\",\n",
    "        \"Is Operator/Contractor Country Match\",\n",
    "    ]\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315ba9b",
   "metadata": {},
   "source": [
    "#### SpaceX\n",
    "There are a lot of Starlink satellites in the sky. Let's create a boolean to flag these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Is SpaceX\"] = df[\"Operator\"] == \"SpaceX\"\n",
    "df[\"Is SpaceX\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb1854",
   "metadata": {},
   "source": [
    "#### Finished\n",
    "That's it! Let's get to analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"data/ucs_satellite_cleaned.csv\"\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"File written to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41eb075",
   "metadata": {},
   "source": [
    "![Loose Ends, Long Goodbyes Sat 2](img/lelg_sat_2_small.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
